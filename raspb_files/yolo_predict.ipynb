{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions by processing videos and giving a video as an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Load YOLO ONNX model\n",
    "model = YOLO(\"C:/Users/aykaq/Downloads/Hornet_detection_20-01/raspb_files/Final_11/weights/best.pt\")\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"C:/Users/aykaq/Downloads/Hornet_detection_20-01/GP047419 4m40 GOED - Trim.MP4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define output video writer\n",
    "output_path = \"C:/Users/aykaq/Downloads/Hornet_detection_20-01/GP047419 14-02 - Trim.MP4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Store detected hornet colors for re-identification\n",
    "hornet_colors = {}\n",
    "next_hornet_id = 0  \n",
    "\n",
    "def extract_dominant_color(image, box):\n",
    "    \"\"\"Extracts dominant color from detected hornet.\"\"\"\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    \n",
    "    if x2 <= x1 or y2 <= y1:  \n",
    "        return (60, 255)  # Default to a stable greenish hue in HSV\n",
    "\n",
    "    hornet_crop = image[y1:y2, x1:x2]\n",
    "\n",
    "    if hornet_crop.size == 0:\n",
    "        return (60, 255)  # Return a stable color if no valid pixels\n",
    "\n",
    "    # Convert to HSV (Hue-Saturation-Value)\n",
    "    hsv_crop = cv2.cvtColor(hornet_crop, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute histogram to find dominant color\n",
    "    hist = cv2.calcHist([hsv_crop], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "    h, s = np.unravel_index(np.argmax(hist), hist.shape)\n",
    "\n",
    "    return (h, s)  # Keep HSV values for consistency\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  \n",
    "\n",
    "    # Run YOLO inference\n",
    "    results = model.predict(frame, imgsz=640, conf=0.5)\n",
    "    \n",
    "    if not results or len(results[0].boxes) == 0:  \n",
    "        print(\"âš ï¸ No detections in this frame.\")\n",
    "        out.write(frame)  # Still write the frame even if no detections\n",
    "        cv2.imshow(\"Hornet Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        continue  \n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.cpu().numpy()\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "            confidence = float(box.conf[0])\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Extract dominant color\n",
    "            detected_color = extract_dominant_color(frame, (x1, y1, x2, y2))\n",
    "\n",
    "            # Match hornet by color\n",
    "            matched_id = None\n",
    "\n",
    "            for hornet_id, stored_color in hornet_colors.items():\n",
    "                if euclidean(detected_color, stored_color) < 20:  \n",
    "                    matched_id = hornet_id\n",
    "                    break\n",
    "\n",
    "            # Assign new ID if no match\n",
    "            if matched_id is None:\n",
    "                matched_id = next_hornet_id\n",
    "                hornet_colors[matched_id] = detected_color\n",
    "                next_hornet_id += 1\n",
    "\n",
    "            print(f\"âœ… Detected Hornet {matched_id} | Color: {detected_color}\")\n",
    "\n",
    "            # Draw bounding box & label\n",
    "            box_color = (int(detected_color[0] * 1.4), int(detected_color[1] * 1.4), 255)\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), box_color, 2)\n",
    "            label = f\"Hornet {matched_id}: {confidence:.2f}\"\n",
    "            cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color, 2)\n",
    "\n",
    "            # Save frame when a hornet is detected\n",
    "            frame_name = f\"/home/on8ei/BeeSafe/detections/hornetl_{matched_id}.jpg\"\n",
    "            cv2.imwrite(frame_name, frame)\n",
    "\n",
    "    # Write processed frame\n",
    "    out.write(frame)\n",
    "\n",
    "    # Show detections\n",
    "    cv2.imshow(\"Hornet Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"âœ… Detection complete. Video saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the format to ONNX to export the model to the raspberry pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO(\"C:/Users/aykaq/Downloads/Hornet_detection_20-01/raspb_files/Final_11/weights/best.pt\")  # Make sure to use your trained model\n",
    "\n",
    "# Export the model to NCNN format\n",
    "model.export(format=\"onnx\")  # Creates 'best_ncnn_model'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the camera  (change the path to do it on py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO ONNX model\n",
    "model = YOLO(\"/home/on8ei/BeeSafe/best.onnx\")\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"âŒ Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"âŒ Error: Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    # Run YOLO inference\n",
    "    results = model.predict(frame, imgsz=640, conf=0.5)  # Lower confidence to detect more\n",
    "\n",
    "    hornet_detected = False  # Track if hornet is found in this frame\n",
    "\n",
    "    print(f\"ðŸ“¢ Raw Model Output: {results}\")  # Debugging: Print detection output\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "            confidence = float(box.conf[0])\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            print(f\"ðŸŸ¢ Detection: x1={x1}, y1={y1}, x2={x2}, y2={y2}, conf={confidence}, class={class_id}\")\n",
    "\n",
    "            if class_id == 0 and confidence > 0.1:  # Lowered confidence\n",
    "                hornet_detected = True\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                label = f\"Hornet: {confidence:.2f}\"\n",
    "                cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    if hornet_detected:\n",
    "        frame_path = f\"/home/on8ei/BeeSafe/detected_frame_{frame_count}.jpg\"\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "        print(f\"âœ… Hornet detected! Frame saved: {frame_path}\")\n",
    "        frame_count += 1\n",
    "\n",
    "    # **REMOVE `cv2.imshow()` due to SSH issues**\n",
    "    cv2.imshow(\"Hornet Detection\", frame)  \n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"ðŸ“Œ Camera stream stopped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions live with camera connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Load YOLO ONNX model\n",
    "model = YOLO(\"/home/on8ei/BeeSafe/best.onnx\")  # Load ONNX model\n",
    "\n",
    "# Open camera (use 0, 1, or 2 depending on your camera index)\n",
    "cap = cv2.VideoCapture(0)  # Change to 1 or 2 if needed\n",
    "\n",
    "# Set camera resolution (Optional)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# Storage for hornet colors & re-identification\n",
    "hornet_colors = {}\n",
    "next_hornet_id = 0  # ID counter for new hornets\n",
    "\n",
    "def extract_dominant_color(image, box):\n",
    "    \"\"\"Extracts dominant color from the detected hornet region.\"\"\"\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "    # Ensure the bounding box is valid\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return None  \n",
    "\n",
    "    hornet_crop = image[y1:y2, x1:x2]\n",
    "\n",
    "    # If crop is empty, return a default color\n",
    "    if hornet_crop.size == 0:\n",
    "        return None  \n",
    "\n",
    "    # Convert to HSV color space\n",
    "    hsv_crop = cv2.cvtColor(hornet_crop, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute **mean HSV** (instead of just histogram max)\n",
    "    mean_color = np.mean(hsv_crop, axis=(0, 1))\n",
    "\n",
    "    return (int(mean_color[0]), int(mean_color[1]))  # Keep Hue & Saturation only\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"âš ï¸ Camera not detected. Check connection.\")\n",
    "        break  \n",
    "\n",
    "    # Run YOLO inference\n",
    "    results = model.predict(frame, imgsz=640, conf=0.1)\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.cpu().numpy()\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "            confidence = float(box.conf[0])\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Extract dominant color of the detected hornet\n",
    "            detected_color = extract_dominant_color(frame, (x1, y1, x2, y2))\n",
    "\n",
    "            if detected_color:\n",
    "                matched_id = None\n",
    "\n",
    "                # **Re-identify hornets based on color similarity**\n",
    "                for hornet_id, stored_color in hornet_colors.items():\n",
    "                    if euclidean(detected_color, stored_color) < 30:  # Looser threshold\n",
    "                        matched_id = hornet_id\n",
    "                        break\n",
    "\n",
    "                # If no match, assign a new ID\n",
    "                if matched_id is None:\n",
    "                    matched_id = next_hornet_id\n",
    "                    hornet_colors[matched_id] = detected_color\n",
    "                    next_hornet_id += 1\n",
    "\n",
    "                print(f\"âœ… Detected Hornet {matched_id} | Color: {detected_color}\")\n",
    "\n",
    "                # Convert HSV to BGR for display\n",
    "                box_color = cv2.cvtColor(\n",
    "                    np.uint8([[[detected_color[0], detected_color[1], 255]]]),\n",
    "                    cv2.COLOR_HSV2BGR)[0][0]\n",
    "                box_color = tuple(int(c) for c in box_color)\n",
    "\n",
    "                # Draw bounding box & label\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), box_color, 2)\n",
    "                label = f\"Hornet {matched_id}: {confidence:.2f}\"\n",
    "                cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color, 2)\n",
    "\n",
    "                # Save frame when a hornet is detected\n",
    "                frame_name = f\"/home/on8ei/BeeSafe/detections/hornet_{matched_id}.jpg\"\n",
    "                cv2.imwrite(frame_name, frame)\n",
    "\n",
    "      # **Save frame only if a hornet was detected**\n",
    "\n",
    "    # **Show detections while running**\n",
    "    cv2.imshow(\"Hornet Detection Live\", frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"âœ… Live detection stopped. All detected hornet images saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a hornet is detected the led goes on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import RPi.GPIO as GPIO\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# **Relay GPIO Setup**\n",
    "RELAY_PIN = 17  # Adjust to your GPIO pin\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "GPIO.setup(RELAY_PIN, GPIO.OUT)\n",
    "GPIO.output(RELAY_PIN, GPIO.LOW)  # Ensure relay is off at start\n",
    "\n",
    "# Load YOLO ONNX model\n",
    "model = YOLO(\"/home/on8ei/BeeSafe/Final_11/weights/best.pt\")\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"/home/on8ei/BeeSafe/GOPR7413 - Trim.MP4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define output video writer\n",
    "output_path = \"/home/on8ei/BeeSafe/hornet-14-02 captured.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Store detected hornet colors for re-identification\n",
    "hornet_colors = {}\n",
    "next_hornet_id = 0  \n",
    "\n",
    "# Function to extract dominant color\n",
    "def extract_dominant_color(image, box):\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    \n",
    "    if x2 <= x1 or y2 <= y1:  \n",
    "        return (60, 255)  # Default greenish hue in HSV\n",
    "\n",
    "    hornet_crop = image[y1:y2, x1:x2]\n",
    "\n",
    "    if hornet_crop.size == 0:\n",
    "        return (60, 255)  \n",
    "\n",
    "    hsv_crop = cv2.cvtColor(hornet_crop, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv_crop], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "    h, s = np.unravel_index(np.argmax(hist), hist.shape)\n",
    "\n",
    "    return (h, s)\n",
    "\n",
    "# Main loop\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  \n",
    "\n",
    "    # Run YOLO inference\n",
    "    results = model.predict(frame, imgsz=640, conf=0.5)\n",
    "    \n",
    "    hornet_detected = False  # Track if a hornet is found\n",
    "\n",
    "    if results and len(results[0].boxes) > 0:  \n",
    "        for result in results:\n",
    "            boxes = result.boxes.cpu().numpy()\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                confidence = float(box.conf[0])\n",
    "\n",
    "                # Extract dominant color\n",
    "                detected_color = extract_dominant_color(frame, (x1, y1, x2, y2))\n",
    "\n",
    "                # Match hornet by color\n",
    "                matched_id = None\n",
    "                for hornet_id, stored_color in hornet_colors.items():\n",
    "                    if euclidean(detected_color, stored_color) < 20:  \n",
    "                        matched_id = hornet_id\n",
    "                        break\n",
    "\n",
    "                if matched_id is None:\n",
    "                    matched_id = next_hornet_id\n",
    "                    hornet_colors[matched_id] = detected_color\n",
    "                    next_hornet_id += 1\n",
    "\n",
    "                print(f\"âœ… Detected Hornet {matched_id} | Color: {detected_color}\")\n",
    "\n",
    "                # Ensure color values are integers\n",
    "                box_color = tuple(map(int, (detected_color[0] * 1.4, detected_color[1] * 1.4, 255)))\n",
    "\n",
    "                # Draw bounding box & label\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), box_color, 2)\n",
    "                label = f\"Hornet {matched_id}: {confidence:.2f}\"\n",
    "                cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color, 2)\n",
    "\n",
    "                # Save frame when a hornet is detected\n",
    "                frame_name = f\"/home/on8ei/BeeSafe/detections/hornet_{matched_id}.jpg\"\n",
    "                cv2.imwrite(frame_name, frame)\n",
    "\n",
    "                hornet_detected = True  # Hornet found\n",
    "\n",
    "    # **Trigger relay if a hornet is detected**\n",
    "    if hornet_detected:\n",
    "        GPIO.output(RELAY_PIN, GPIO.HIGH)  # Turn ON light\n",
    "        print(\"ðŸ”´ LIGHT ON: Hornet detected!\")\n",
    "    else:\n",
    "        GPIO.output(RELAY_PIN, GPIO.LOW)   # Turn OFF light\n",
    "        print(\"ðŸŸ¢ LIGHT OFF: No hornets detected.\")\n",
    "\n",
    "    # Write processed frame\n",
    "    out.write(frame)\n",
    "\n",
    "    # Show detections\n",
    "    cv2.imshow(\"Hornet Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "GPIO.cleanup()  # Cleanup GPIO\n",
    "\n",
    "print(f\"âœ… Detection complete. Video saved as {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
